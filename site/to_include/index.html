<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        
        <link rel="shortcut icon" href="../img/favicon.ico">
        <title>To include - Bioinformatics</title>
        <link href="../css/bootstrap-custom.min.css" rel="stylesheet">
        <link href="../css/font-awesome.min.css" rel="stylesheet">
        <link href="../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/color-brewer.min.css">
        <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
            <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
        <![endif]-->

        <script src="../js/jquery-1.10.2.min.js" defer></script>
        <script src="../js/bootstrap-3.0.3.min.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script> 
    </head>

    <body>

        <div class="navbar navbar-default navbar-fixed-top" role="navigation">
            <div class="container">

                <!-- Collapsed navigation -->
                <div class="navbar-header">
                    <!-- Expander button -->
                    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                        <span class="sr-only">Toggle navigation</span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </button>
                    <a class="navbar-brand" href="..">Bioinformatics</a>
                </div>

                <!-- Expanded navigation -->
                <div class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li >
                                <a href="..">Home</a>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="dropdown-toggle" data-toggle="dropdown">Databases <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li >
    <a href="../databases/">General</a>
</li>
                                    
<li >
    <a href="../emboss/">EMBOSS</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="dropdown-toggle" data-toggle="dropdown">Shell <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li >
    <a href="../shell/">Basics</a>
</li>
                                    
<li >
    <a href="../fasta/">Fasta Manipulation</a>
</li>
                                    
<li >
    <a href="../shell_adv/">Advanced Commands & Installation</a>
</li>
                                    
<li >
    <a href="../git/">Git</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="dropdown-toggle" data-toggle="dropdown">Python <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li >
    <a href="../python/">Basics</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="dropdown-toggle" data-toggle="dropdown">R <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li >
    <a href="../R/">R</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="dropdown-toggle" data-toggle="dropdown">Tools <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li >
    <a href="../atom/">Atom Editor</a>
</li>
                                    
<li >
    <a href="../mkdocs/">mkdocs</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="dropdown-toggle" data-toggle="dropdown">Sequencing <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li >
    <a href="../programs/">Programms</a>
</li>
                                    
<li >
    <a href="../illumina/">HTS (Illumina)</a>
</li>
                                    
<li >
    <a href="../nanopore/">Longreads (Nanopore)</a>
</li>
                                    
<li >
    <a href="../hybrid/">Hybridassembly</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="dropdown-toggle" data-toggle="dropdown">Other Topics <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li >
    <a href="../gwas/">GWAS</a>
</li>
                                    
<li >
    <a href="../gs/">GS</a>
</li>
                                </ul>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav navbar-right">
                        <li>
                            <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
                <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
        <li class="main active"><a href="#overview-of-the-bioinformatic-course">Overview of the Bioinformatic Course</a></li>
            <li><a href="#tags-bioinformatics-overview">tags: bioinformatics overview</a></li>
            <li><a href="#downloading-from-ncbi">Downloading from NCBI</a></li>
            <li><a href="#blast-ncbi-example-command">BLAST (ncbi+ example command)</a></li>
        <li class="main "><a href="#07-rnaseq-overview">07 - RNAseq overview</a></li>
            <li><a href="#overview">Overview</a></li>
            <li><a href="#differential-expression-practical">Differential Expression - practical</a></li>
        <li class="main "><a href="#08-metagenomics">08 - Metagenomics</a></li>
            <li><a href="#overview-terminology">Overview &amp; Terminology</a></li>
            <li><a href="#whole-metagenome-sequencing-practical">Whole Metagenome Sequencing - practical</a></li>
            <li><a href="#metagenome-assembly-and-binning-practical">Metagenome assembly and binning - practical</a></li>
        <li class="main "><a href="#09-metabarcoding">09 - Metabarcoding</a></li>
            <li><a href="#overview_1">Overview</a></li>
            <li><a href="#biodiversity">Biodiversity</a></li>
        <li class="main "><a href="#10-ugene">10 - UGENE</a></li>
        <li class="main "><a href="#11-epigenetics">11 - Epigenetics</a></li>
            <li><a href="#overview_2">Overview</a></li>
        <li class="main "><a href="#12-genome-annotation">12 - Genome annotation</a></li>
            <li><a href="#structural-genome-annotation">Structural genome annotation</a></li>
            <li><a href="#genome-annotation-with-augustus-practical">Genome annotation with augustus - practical</a></li>
            <li><a href="#running-the-maker-gene-build-pipeline-practical">Running the maker gene build pipeline - practical</a></li>
            <li><a href="#functional-genome-annotation">Functional genome annotation</a></li>
            <li><a href="#interproscan-approach-practical">Interproscan approach - practical</a></li>
            <li><a href="#blast-approach-practical">BLAST approach - practical</a></li>
        <li class="main "><a href="#13-other-useful-informations">13 - Other useful informations</a></li>
            <li><a href="#uppmax-cloud">UPPMAX Cloud</a></li>
            <li><a href="#slurm-work-flow">Slurm work flow</a></li>
    </ul>
</div></div>
                <div class="col-md-9" role="main">

<h1 id="overview-of-the-bioinformatic-course">Overview of the Bioinformatic Course</h1>
<p>[toc]</p>
<h6 id="tags-bioinformatics-overview">tags: <code>bioinformatics</code> <code>overview</code></h6>
<hr />
<p>Lecturers git hub:
-   <a href="https://github.com/HadrienG">Hadrien Gourlé</a>
    - <a href="https://sgbc.github.io/course/">Course site of Hadrien</a>
-   <a href="https://github.com/jhayer">Juliette Hayer</a>
-   <a href="https://github.com/Ackia">Oskar Karlsson</a></p>
<p>Another good genomics tutorial can be found <a href="https://genomics.sschmeier.com/introduction.html">here</a></p>
<h2 id="downloading-from-ncbi">Downloading from NCBI</h2>
<pre><code class="bash">#from the sra-toolkit, use git hub
fastq-dump &lt;accessionnumber&gt;
</code></pre>

<h2 id="blast-ncbi-example-command">BLAST (ncbi+ example command)</h2>
<p><code>-outfmt 6</code> creates tab delimited file, for options see <code>--help</code>  </p>
<pre><code class="bash">blastp -query *inputfile* -db *database* -out *outputfile* -outfmt &quot;6 qseqid length evalue&quot;
</code></pre>

<h1 id="07-rnaseq-overview">07 - RNAseq overview</h1>
<h2 id="overview">Overview</h2>
<ul>
<li>identifying noval transcripts and splicing variants</li>
<li>Measuring gene expression (cellular identity, expression in response to stimuli, differences between health/sick, correlation to diseases, etc.)</li>
<li>microRNA's, RNA editing</li>
<li>low background noise, high technical reproducibility</li>
</ul>
<h3 id="typical-rnaseq-workflow">Typical RNAseq workflow</h3>
<p><strong>Questions:</strong>
<em>Quantification</em>: Expression rates
<em>Splicing variants</em>: exon arrangements
<em>Novel transcripts</em>
<em>RNA editing</em>: single nucleotide variations (SNV)</p>
<p><strong>Practical:</strong>
 1) poly-A RNA extraction (mRNA extraction Kit)
 2) reverse transcription into c-DNA
 3) shearing (for illumina, not for nanopore)
 4) library prep (depends on which seq. technique)
 5) sequencing and getting the reads (fastq)</p>
<p><strong>Bioinformatics:</strong>
 1) <strong>Preprocessing</strong> fastq files using: <code>Trimmomatic, cutadapt, trimgalore</code>
    1) adapter removal
    2) trimming of bad quality
 2) <strong>Mapping</strong>
     1) no genome: <em>de novo</em> transcriptom construction
     2) known genome: align reads against it
         a) <em>Quantification</em>: accept only known/described transcripts
         b) <em>Splicing variants</em>: allow alternate arrangements of known transcripts
         c) <em>Novel transcripts</em>: allow alignment to exons and other regions
 3) <strong>Mapping QC</strong> with <code>RNA-SeQC</code>, discard reads if:
    1) cannot be uniquely mapped
    2) alignment overlaps with several genes
    3) bad alignment quality score
    4) paired-end reads (illumina) do not map to the same genes
 4) <strong>Expression Quantification</strong> (normalization of read counts)
    1) correct read length bias (longer genes produce more reads)
    2) correct Batch effects (labs and preparation time - different coverage between samples)
    3) correct technical biases (use of different machines)</p>
<h3 id="types-of-normalization">Types of normalization</h3>
<p>You need to know:
<em> How was RNA extracted and the library build
</em> Which Sequencing platform
<em> single or basepaired ends?
</em> How many reads per sample?
* QC reports?</p>
<p>Normalization for: <strong>library size</strong>, <strong>gene length</strong>, <strong>RNA composition</strong> (comparison between samples)
* Methods:
    * RPKM/FPKM (size and length)
        * not recomended if you compare between different samples
        * <strong>R</strong>eads <strong>p</strong>er <strong>k</strong>ilo base per <strong>m</strong>illion mapped reads (RPKM)
        * use only to report expression values NOT differential expression
    * TPM (size and length)
        * similar to RPKM but uses <strong>t</strong>ranscripts instead of reads
        * the presenter doesn't use this method
    * TMM and DESeq (size and composition)
        * TMM considers the tissue type expression variation
        * suitable for differential expression between sample groups</p>
<p><strong>For data visualization is done with MA-plot or vulcano plot</strong>(check the tutorial afterwards)</p>
<blockquote>
<p><img alt="" src="https://raw.githubusercontent.com/wiki/trinityrnaseq/trinityrnaseq/images/MA_and_volcano_plot.png" />
Figure: Black is not significant, red are significant changes
<em> heatmaps is the most common representation for differential expression analysis (R/Bioconducter heatmap and ggplot package)
</em> Another way to see how samples cluster is with PCA plots</p>
</blockquote>
<p>Function enrichment analysis:
<em> GOSeq/topGO/GAGE (R package)
</em> <a href="https://david.ncifcrf.gov/">DAVID</a></p>
<h2 id="differential-expression-practical">Differential Expression - practical</h2>
<p>For this tutorial we used the test data from <a href="http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004393">this paper</a>. This is a highly comprehensive tutorial paper for RNAseq.
<strong>Summary:</strong></p>
<blockquote>
<p>[color=lightblue]
<em> We have two <strong>two commercially available RNA samples</strong>:
  * Universal Human Reference (UHR)
      * 10 cancer cell lines
  * Human Brain Reference (HBR)
      * isolated from brains of 23 Caucasians (m &amp; f) mostly 60-80 years old
</em> <strong>a spike-in control was added to each sample</strong> (ERCC ExFold RNA). <strong>Spike-in consists of 92 transcripts</strong> that are present in known concentrations across a wide abundance range (from very few copies to many copies). This <strong>allows to test</strong> the degree to which the <strong>RNA-seq assay</strong> (including all laboratory and analysis steps) accurately <strong>reflects the relative abundance</strong> of transcript species within a sample</p>
<ul>
<li><strong>two 'mixes' of spike-in control</strong> to allow assessment of differential expression output between samples</li>
<li>
<p><strong>3 complete experimental replicates</strong> for each sample to assess the technical variability of our overall process of producing RNA-seq data in the lab</p>
</li>
<li>
<p>UHR + ERCC Spike-In Mix1, Replicate 1</p>
</li>
<li>UHR + ERCC Spike-In Mix1, Replicate 2</li>
<li>UHR + ERCC Spike-In Mix1, Replicate 3</li>
<li>HBR + ERCC Spike-In Mix2, Replicate 1</li>
<li>HBR + ERCC Spike-In Mix2, Replicate 2</li>
<li>HBR + ERCC Spike-In Mix2, Replicate 3</li>
<li>For technical details, like Kits, rRNA removal, sample concentrations etc. read the <a href="https://doi.org/10.1371/journal.pcbi.1004393.s002">S2 Data</a> file from the paper.</li>
</ul>
</blockquote>
<p>Data available at:</p>
<pre><code class="bash">curl -O -J -L https://osf.io/7zepj/download
tar xzf toy_rna.tar.gz
</code></pre>

<h3 id="salmon-for-indexing-and-quantification-of-reads"><code>salmon</code> for indexing and quantification of reads</h3>
<ul>
<li>Salmon produces highly-accurate, transcript-level quantification estimates from RNA-seq data (you need another - splice aware program - if you are interested in new transcripts or splice sides.</li>
</ul>
<p><strong>Quantify reads with <code>salmon</code></strong></p>
<ul>
<li>First Indexing:</li>
</ul>
<pre><code class="bash">salmon index -t chr22_transcripts.fa -i chr22_index
</code></pre>

<ul>
<li>Now quantifying with this loop:</li>
<li>simply goes through each sample and invokes salmon using basic options:</li>
<li><code>-i</code> index file from the command before</li>
<li><code>--libType</code> A tells salmon that it should automatically determine the library type of the sequencing reads (e.g. stranded vs. unstranded etc.)</li>
<li>the -1 and -2 arguments tell salmon where to find the left and right reads for this sample (salmon accepts gzipped FASTQ files)</li>
<li><code>-o</code> output</li>
</ul>
<pre><code class="bash">for i in *_R1.fastq.gz
do
   prefix=$(basename $i _R1.fastq.gz)
   salmon quant -i chr22_index --libType A \
          -1 ${prefix}_R1.fastq.gz -2 ${prefix}_R2.fastq.gz -o quant/${prefix};
done
</code></pre>

<ul>
<li>in the output folder (quant folder) is the quant.sf file we use for Rstudio.</li>
</ul>
<h3 id="r-studio-analysis">R-studio analysis</h3>
<ul>
<li>In R-studio set your working directory to the data (chr22_genes.gtf is visible)</li>
<li>load the necessary modules</li>
</ul>
<pre><code class="R">library(tximport)
library(GenomicFeatures)
library(readr)
</code></pre>

<ul>
<li>Salmon did the quantification of the transcript level. We want to see which genes are differentially expressed, so we need to link the transcript names to the gene names. We can use our .gtf annotation for that, and the GenomicFeatures package:</li>
</ul>
<pre><code class="R">txdb &lt;- makeTxDbFromGFF(&quot;chr22_genes.gtf&quot;)
k &lt;- keys(txdb, keytype = &quot;TXNAME&quot;)
tx2gene &lt;- select(txdb, keys = k, keytype = &quot;TXNAME&quot;, columns = &quot;GENEID&quot;)
</code></pre>

<ul>
<li>Now we can import the salmon quantification.</li>
</ul>
<pre><code class="R">#we imported a file were each sample name is stored under the column &quot;sample&quot;
    samples &lt;- read.table(&quot;samples.txt&quot;, header = TRUE)
#we save the path to each quant.sf file using the name of each sample in the samples file
    files &lt;- file.path(&quot;quant&quot;, samples$sample, &quot;quant.sf&quot;)
#we renamed the columns name of each path we extracted
    names(files) &lt;- paste0(samples$sample)
#imports the quant files, txi.salmon is a datalist e.g. salmon$counts for the counts list-entry
    txi.salmon &lt;- tximport(files, type = &quot;salmon&quot;, tx2gene = tx2gene)
</code></pre>

<p><strong>Differential expression using DESeq2</strong>
+ <code>DESeqDataSet</code> is a subclass of <code>RangedSummarizedExperiment</code>, used to store the input values, intermediate calculations and results of an <strong>analysis of differential expression</strong>.</p>
<pre><code class="R">library(DESeq2) #loading module
</code></pre>

<ul>
<li>Instantiate the DESeqDataSet and generate result table. See <code>?DESeqDataSetFromTximport</code> and <code>?DESeq</code> for more information.</li>
</ul>
<pre><code class="R">dds &lt;- DESeqDataSetFromTximport(txi.salmon, samples, ~condition)
dds &lt;- DESeq(dds)
res &lt;- results(dds) #summary(res) to see the results
</code></pre>

<ul>
<li>DESeq uses a negative binomial distribution. Such distributions have two parameters: <strong>mean</strong> and <strong>dispersion</strong>.</li>
<li>So we can do a dispersion plot with the dispersion data:</li>
</ul>
<pre><code class="R">plotDispEsts(dds, main=&quot;Dispersion plot&quot;)
</code></pre>

<ul>
<li>Explanations about dispersion and DESeq2 can be found in this very good tutorial <a href="https://hbctraining.github.io/DGE_workshop/lessons/04_DGE_DESeq2_analysis.html">here</a>.</li>
</ul>
<blockquote>
<p><img alt="" src="https://i.imgur.com/4q4cmxH.png" />
Figure:  The red line in the figure plots the estimate for the <strong>expected dispersion value for genes of a given expression strength</strong>. Each black dot is a gene with an associated mean expression level and maximum likelihood estimation (MLE) of the dispersion.</p>
</blockquote>
<hr />
<p><strong>Heatmap</strong>
* For clustering and heatmaps, we need to log transform our data:</p>
<pre><code class="R">rld &lt;- rlogTransformation(dds) #log of data from &quot;dds&quot;
#loading librarys for plot
library(RColorBrewer)
library(gplots)
</code></pre>

<ul>
<li>parameters of the heatmap:</li>
</ul>
<pre><code class="R">(mycols &lt;- brewer.pal(8, &quot;Dark2&quot;)[1:length(unique(samples$condition))])
sampleDists &lt;- as.matrix(dist(t(assay(rld))))
heatmap.2(as.matrix(sampleDists), key=F, trace=&quot;none&quot;,
          col=colorpanel(100, &quot;black&quot;, &quot;white&quot;),
          ColSideColors=mycols[samples$condition],
          RowSideColors=mycols[samples$condition],
          margin=c(10, 10), main=&quot;Sample Distance Matrix&quot;)
</code></pre>

<blockquote>
<p><img alt="" src="https://i.imgur.com/i6NEzsu.png" />
Figure: Differential Expression Analysis: Comparison between each samples as a heatmap, black is identical, white not identical</p>
</blockquote>
<hr />
<p><strong>PCA Plot</strong></p>
<pre><code class="R">DESeq2::plotPCA(rld, intgroup=&quot;condition&quot;)
</code></pre>

<p><img alt="" src="https://i.imgur.com/HOizOAe.png" /></p>
<hr />
<p><strong>MA plot and the Volcano Plot</strong></p>
<ul>
<li>we create, merge and sort data, so its readable for te plots</li>
</ul>
<pre><code class="R">table(res$padj&lt;0.05) #extract data out of res
res &lt;- res[order(res$padj), ] #sorting the res variable
#merging data so its ready for plots
resdata &lt;- merge(as.data.frame(res), as.data.frame(counts(dds, normalized=TRUE)), by=&quot;row.names&quot;, sort=FALSE)
names(resdata)[1] &lt;- &quot;Gene&quot;
</code></pre>

<ul>
<li>You can take a look at the p-values we sorted in the variable <code>res</code>, using these plots:</li>
</ul>
<pre><code class="R">hist(res$pvalue, breaks=50, col=&quot;grey&quot;) #a hist plot
DESeq2::plotMA(dds, ylim=c(-1,1), cex=1) #an MA plot
</code></pre>

<ul>
<li>now we do the actual vulcano plot</li>
</ul>
<pre><code class="R"># Volcano plot
with(res, plot(log2FoldChange, -log10(pvalue), pch=20, main=&quot;Volcano plot&quot;, xlim=c(-2.5,2)))
# second one highlighting certain points
with(subset(res, padj&lt;.05 ), points(log2FoldChange, -log10(pvalue), pch=20, col=&quot;red&quot;))
</code></pre>

<hr />
<h3 id="kegg-pathway-analysis">KEGG pathway analysis</h3>
<p><strong>KEGG PATHWAY</strong> is a collection of manually drawn <a href="http://www.genome.jp/kegg/kegg3a.html">pathway maps</a> representing our knowledge on the molecular interaction, reaction and relation networks for:
* We need these librarys:</p>
<pre><code class="R">library(AnnotationDbi)
library(org.Hs.eg.db)
library(pathview)
library(gage)
library(gageData)
</code></pre>

<ul>
<li>Using the <code>mapIds</code> function to add more columns to the results</li>
<li>the row.names of our results table has the Ensembl gene ID (our key), so we need to specify <code>keytype=ENSEMBL</code></li>
<li>the column argument tells the <code>mapIds</code> function which information we want</li>
<li>the <code>multiVals</code> argument tells the function what to do if there are multiple possible values for a single input value (we take only the first entry if we have more than two)</li>
</ul>
<pre><code class="R">res$symbol &lt;- mapIds(org.Hs.eg.db, keys=row.names(res), column=&quot;SYMBOL&quot;, keytype=&quot;ENSEMBL&quot;, multiVals=&quot;first&quot;)
res$entrez &lt;- mapIds(org.Hs.eg.db, keys=row.names(res), column=&quot;ENTREZID&quot;, keytype=&quot;ENSEMBL&quot;, multiVals=&quot;first&quot;)
res$name &lt;- mapIds(org.Hs.eg.db, keys=row.names(res), column=&quot;GENENAME&quot;, keytype=&quot;ENSEMBL&quot;, multiVals=&quot;first&quot;)
</code></pre>

<ul>
<li>We’re going to use the <a href="https://bioconductor.org/packages/release/bioc/html/gage.html">gage</a> package for pathway analysis, and the <a href="https://bioconductor.org/packages/release/bioc/html/pathview.html">pathview</a> package to draw a pathway diagram.</li>
<li>The gageData package has pre-compiled databases mapping genes to KEGG pathways and GO terms for common organisms:</li>
</ul>
<pre><code class="R">data(kegg.sets.hs)
data(sigmet.idx.hs)
kegg.sets.hs &lt;- kegg.sets.hs[sigmet.idx.hs]
head(kegg.sets.hs, 3)
</code></pre>

<ul>
<li>Run the pathway analysis</li>
</ul>
<pre><code class="R">foldchanges &lt;- res$log2FoldChange
names(foldchanges) &lt;- res$entrez
keggres &lt;- gage(foldchanges, gsets=kegg.sets.hs, same.dir=TRUE)
lapply(keggres, head)
</code></pre>

<ul>
<li>Now we need to identify which pathway we have and whats the ID of it:</li>
</ul>
<pre><code class="R">library(dplyr)
# Get the pathways
keggrespathways &lt;- data.frame(id=rownames(keggres$greater), keggres$greater) %&gt;%
  tbl_df() %&gt;%
  filter(row_number()&lt;=5) %&gt;%
  .$id %&gt;%
  as.character()
keggrespathways
# Get the IDs.
keggresids &lt;- substr(keggrespathways, start=1, stop=8)
</code></pre>

<ul>
<li>Finally, the <code>pathview()</code> function in the pathview package makes the plots. Let’s write a function so we can loop through and draw plots for the top 5 pathways we created above.</li>
</ul>
<pre><code class="bash"># Define plotting function for applying later
    plot_pathway &lt;- function(pid) pathview(gene.data=foldchanges, pathway.id=pid, species=&quot;hsa&quot;, new.signature=FALSE)

# Unload dplyr since it conflicts with the next line
    detach(&quot;package:dplyr&quot;, unload=T)
# plot multiple pathways (plots saved to disk andreturns a throwaway list object)
    tmp &lt;- sapply(keggresids, function(pid) pathview(gene.data=foldchanges, pathway.id=pid, species=&quot;hsa&quot;))
</code></pre>

<p><strong>The results are shown here (but only for 2 pathways and only the KEGG output):</strong></p>
<blockquote>
<p><img alt="" src="https://i.imgur.com/5MJxT3b.png" />
<img alt="" src="https://i.imgur.com/6jWXmGt.png" /></p>
</blockquote>
<p>Another tutorial about this pathway stuff can be found <a href="http://www.gettinggeneticsdone.com/2015/12/tutorial-rna-seq-differential.html">here</a>.</p>
<h1 id="08-metagenomics">08 - Metagenomics</h1>
<h2 id="overview-terminology">Overview &amp; Terminology</h2>
<ul>
<li>collected genomic information of a sample</li>
<li>unbiased targeting (no special marker like metabarcoding)</li>
<li>Metabarcoding (16S) is used for large number of samples, i.e., multiple patients, longitudinal studies, etc. but offers limited taxonomical and functional resolution in comparision</li>
<li><strong>Whole Metagenome sequencing (WMS)</strong>, or shotgun metagenome sequencing, provides insight into community biodiversity and function in contrast to Metabarcoding, where only a specific region of the bacterial community (the 16s rRNA) is sequenced</li>
<li><strong>WMS</strong> aims at sequencing all the genomic material present in the environment</li>
<li><strong>WMS</strong> is more expensive but offers increased resolution, and <strong>allows the discovery of viruses as well as other mobile genetic elements</strong></li>
</ul>
<p><strong>Microbiota</strong>
<em> organism within a set environment
</em> mainly focused on bacteria
* exluding viruses &amp; mobile elements</p>
<p><strong>Microbiome</strong>
<em> includes all factors of an environment
</em> (organism, genetic elements, metabolites, proteins)</p>
<p><strong>Holobiont</strong>
<em> assemblages of different species that form a ecological unit
</em> divided into: virome, microbiome and macrobiological hosts</p>
<h2 id="whole-metagenome-sequencing-practical">Whole Metagenome Sequencing - practical</h2>
<ul>
<li>comparing samples from the Pig Gut Microbiome against the Human Gut Microbiome</li>
</ul>
<p>Software used:
-   <a href="http://www.bioinformatics.babraham.ac.uk/projects/fastqc/">FastQC</a>
-   <a href="https://ccb.jhu.edu/software/kraken/">Kraken</a>
-   <a href="https://www.r-project.org/">R</a>
-   <a href="https://github.com/fbreitwieser/pavian">Pavian</a></p>
<p>Data used:</p>
<pre><code class="bash">curl -O -J -L https://osf.io/h9x6e/download
tar xvf subset_wms.tar.gz
</code></pre>

<ul>
<li>we <code>ssh</code> using additionally the <code>-X</code> flag to allow a graphical interface</li>
<li>we used <code>fastqc</code> do check the quality of our data</li>
</ul>
<h3 id="1-taxonomic-read-assignment-with-kraken">1. Taxonomic read assignment with <code>Kraken</code></h3>
<ul>
<li>first we need the Kraken database</li>
</ul>
<pre><code class="bash">#create a databases directory and download the database
wget https://ccb.jhu.edu/software/kraken/dl/minikraken_20171019_4GB.tgz
tar xzf minikraken_20171019_4GB.tgz
</code></pre>

<ul>
<li>running <code>kraken</code> on the reads</li>
<li><strong>produces a tab-delimited file with an assigned TaxID for each read</strong></li>
</ul>
<pre><code class="bash"># for the script you need to declare the KRAKEN_DB path
KRAKEN_DB=&quot;/mnt/databases/minikraken_20171013_4GB&quot;
for i in *_1.fastq
do
    prefix=$(basename $i _1.fastq)
    # print which sample is being processed
    echo $prefix
    kraken --db $KRAKEN_DB --threads 2 --fastq-input ${prefix}_1_corr.fastq ${prefix}_2_corr.fastq &gt; /home/student/wms/results/${prefix}.tab
    kraken-report --db $KRAKEN_DB /home/student/wms/results/${prefix}.tab &gt; /home/student/wms/results/${prefix}_tax.txt
done
</code></pre>

<h3 id="2-visualization-with-pavian-in-r">2. Visualization with Pavian in R</h3>
<ul>
<li>Installing and run Pavian in R with those commands:</li>
</ul>
<pre><code class="R">#one time only installations and setup
options(repos = c(CRAN = &quot;http://cran.rstudio.com&quot;))
if (!require(remotes)) { install.packages(&quot;remotes&quot;) }
remotes::install_github(&quot;fbreitwieser/pavian&quot;)
#Start up command
pavian::runApp(port=5000)
</code></pre>

<ul>
<li>creates a new R-tab were you can open the kraken files</li>
<li>creates a nice sankey chart of your organism within your sample</li>
<li>its scalable, allows comparision between samples (as a table) and indepth analysis of samples (see figure)</li>
</ul>
<blockquote>
<p>[color=lightgreen]Example results in one sample as a sankey chart using pavian
<img alt="" src="https://i.imgur.com/Lmvswjo.png" /></p>
</blockquote>
<ul>
<li>KRONA chart is also for visualisation of metagenomic data</li>
<li>good for explanation of your sample</li>
<li>but PAVIAN is way better</li>
</ul>
<h2 id="metagenome-assembly-and-binning-practical">Metagenome assembly and binning - practical</h2>
<p>AIM: inspect and assemble metagenomic data and retrieve draft genomes</p>
<ul>
<li>using a mock community of 20 bacteria simulating Illumina HiSeq created with <a href="http://insilicoseq.readthedocs.io">InSilicoSeq</a></li>
<li>selected from the <a href="http://ocean-microbiome.embl.de/companion.html">Tara Ocean study</a> that recovered 957 distinct Metagenome-assembled-genomes (or MAGs) that were previsouly unknown</li>
</ul>
<h3 id="1-correction-and-assembly-of-the-illumina-reads">1. Correction and assembly of the illumina reads</h3>
<ul>
<li>check the fastq data with <code>fastqc</code></li>
<li>do <code>sickle</code> and <code>scythe</code> as needed (see <strong>03 - HTS</strong>)</li>
<li>assembly here with <code>megahit</code></li>
</ul>
<pre><code>sickle pe -f tara_reads_R1.fastq.gz -r tara_reads_R2.fastq.gz -t sanger -o tara_trimmed_R1.fastq -p tara_trimmed_R2.fastq -s /dev/null
megahit -1 tara_trimmed_R1.fastq -2 tara_trimmed_R2.fastq -o tara_assembly
</code></pre>

<h3 id="2-binning">2. Binning</h3>
<ul>
<li>First map the reads back against the assembly (for coverage information)</li>
<li>bowtie2 is a ultra fast short read mapper/aligner</li>
</ul>
<pre><code class="bash">ln -s tara_assembly/final.contigs.fa . #link contigs to current folder
bowtie2-build final.contigs.fa final.contigs #index
bowtie2 -x final.contigs -1 tara_trimmed_R1.fastq -2 tara_trimmed_R2.fastq | samtools view -bS -o tara_to_sort.bam #alignment and bam conversion
samtools sort tara_to_sort.bam -o tara.bam
samtools index tara.bam
</code></pre>

<ul>
<li>then we run <code>metabat</code></li>
</ul>
<pre><code class="bash">runMetaBat.sh -m 1500 final.contigs.fa tara.bam
mv final.contigs.fa.metabat-bins1500 metabat
</code></pre>

<h3 id="3-qc-of-the-bins">3. QC of the bins</h3>
<ul>
<li>first time you run <code>checkm</code> you have to create the database</li>
</ul>
<pre><code class="bash">sudo checkm data setRoot ~/.local/data/checkm
</code></pre>

<pre><code class="bash">checkm lineage_wf -x fa metabat checkm/
checkm bin_qa_plot -x fa checkm metabat plots
</code></pre>

<h3 id="4-get-organism-information-and-plot-it">4. Get organism information and plot it</h3>
<pre><code class="bash">#tells you which organism, saves under checkm/lineage needs folder checkm
checkm qa checkm/lineage.ms checkm
#plots its
checkm bin_qa_plot -x fa checkm metabat plots
</code></pre>

<ul>
<li>you get something like this, which should represent 10 different species (theoretically):
<img alt="" src="https://i.imgur.com/RG2mmkR.png" /></li>
<li>now you can annotate each bin (fasta files are in metabat dir)</li>
<li>more informations can be found <a href="https://www.nature.com/articles/s41564-017-0012-7">here</a> and <a href="https://www.nature.com/articles/sdata2017203">here</a></li>
</ul>
<h3 id="5-barrnap">5. Barrnap</h3>
<ul>
<li><strong>BA</strong>sic <strong>R</strong>apid <strong>R</strong>ibosomal <strong>RNA</strong> <strong>P</strong>redictor</li>
<li>isnt tsuitable for novel stuff since it has to be in the database, but seems still to work (see figure above of unknown marine bacteria)</li>
<li>you can download it <a href="https://github.com/tseemann/barrnap">here</a></li>
</ul>
<h1 id="09-metabarcoding">09 - Metabarcoding</h1>
<h2 id="overview_1">Overview</h2>
<ul>
<li>very biased part since we only look at one very small gene</li>
<li>a rapid method of high-throughput, DNA-based identification of multiple species from a complex and possibly degraded sample of DNA or from mass collection of specimens</li>
<li>16S rRNA regions for genomic classification</li>
<li>not ideal, 23S or more gene would be useful, but most reference only exist on 16S</li>
<li>platform dependent sequence information (short reads is less information)</li>
<li>usually illumina is used because its cheap, but nanopore data or pacbio will be the future standard since the results are way better<blockquote>
<p>Preparation steps for metabarcoding using Illumina.
<img alt="" src="http://media.springernature.com/m685/nature-static/assets/v1/image-assets/srep41948-f1.jpg" /></p>
</blockquote>
</li>
</ul>
<p>Programms to use:
+ <a href="http://qiime.org/">QIIME</a> but its buggy
+ <a href="www.mothur.org/">MOTHUR</a> also buggy
+ <a href="https://www.biorxiv.org/content/early/2015/11/06/030742">WIMP - whats in my pot</a> nanopore approach, its  really good</p>
<h2 id="biodiversity">Biodiversity</h2>
<ul>
<li><strong>α = represents a local habitat/environment/sample</strong><ul>
<li>can be plotted using the <code>plot_richness</code> function of the <code>phylosec</code> package</li>
<li>this is a wrapper featuring 7 plots like "Shannon"</li>
</ul>
</li>
<li><strong>β = is the differences between two α (samples)</strong><ul>
<li>can be plotted using the <code>plot_ordination</code> function of the <code>phylosec</code> package</li>
<li>declare the method first (<code>ord &lt;- ordinate(physeq, 'NMDS', 'bray'</code>)</li>
<li>see below for the different β diversity methods</li>
</ul>
</li>
<li><strong>γ = describes the total diversity of an ecosystem or of all gathered samples</strong></li>
</ul>
<p><strong>Illustration of α, β, and γ diversity:</strong>
<img alt="" src="https://media.springernature.com/lw785/springer-static/image/art%3A10.1007%2Fs00442-008-1190-z/MediaObjects/442_2008_1190_Fig1_HTML.gif" />
Figure: <em>Circles</em> represent α diversity as richness of species (symbols) in a sample (local). <em>Dashed box</em> represents γ diversity (diversity within a set of samples or within a larger region). β diversity describes the differences between samples (β~D~ = similarity; β~P~ = species richness comparision). This is a more complex description and explained in detail in this <a href="https://link.springer.com/article/10.1007/s00442-008-1190-z">paper</a>.</p>
<h3 id="diversity-analysis">β diversity analysis</h3>
<h4 id="plotting-your-data-pca-versus-mda">Plotting your data: PCA versus MDA</h4>
<ul>
<li>Principal Component Analysis (PCA) or Multiple Discriminant Analysis (MDA) both eliminate an axis (e.g. from 3D to 2D) while maximizing the variance on the x-axis, see <a href="http://setosa.io/ev/principal-component-analysis/">example</a></li>
<li>MDA also maximizes the spread of the 2D data</li>
<li>more information <a href="http://sebastianraschka.com/Articles/2014_pca_step_by_step.html">here</a></li>
<li>log-transform is used to filter off trivial effects, which could dominate our PCA</li>
</ul>
<table>
<thead>
<tr>
<th>without log normalization</th>
<th>with log normalization</th>
</tr>
</thead>
<tbody>
<tr>
<td><img alt="" src="https://i.stack.imgur.com/UWYdC.png" /></td>
<td><img alt="" src="https://i.stack.imgur.com/BTanP.png" /></td>
</tr>
<tr>
<td>#### Which distance method to choose for β diversity?</td>
<td></td>
</tr>
<tr>
<td>A overview can be found <a href="https://sites.lifesci.ucla.edu/eeb-kraft/wp-content/uploads/sites/56/2016/01/Anderson_et_al_ELE_2010.pdf">in this publication</a>.</td>
<td></td>
</tr>
<tr>
<td>* identities only = binary; Abundance included = quantitative</td>
<td></td>
</tr>
<tr>
<td>* All methods destinquish whether they exclude or include joint absences:</td>
<td></td>
</tr>
<tr>
<td><img alt="" src="https://i.imgur.com/XVz9EwR.png" /></td>
<td></td>
</tr>
<tr>
<td>## Metabarcoding - practical</td>
<td></td>
</tr>
<tr>
<td><strong>Another detailed tutorial about DADA2 it <a href="https://benjjneb.github.io/dada2/tutorial.html">can be found here</a></strong></td>
<td></td>
</tr>
<tr>
<td>* we use the DADA2 apporach (very extensive manual and very memory efficient while being fast)</td>
<td></td>
</tr>
<tr>
<td>* is a relatively new method to analyse amplicon data which uses exact variants instead of OTUs</td>
<td></td>
</tr>
<tr>
<td>### 1. Install and Load Packages</td>
<td></td>
</tr>
<tr>
<td>* install DADA2 and other necessary packages</td>
<td></td>
</tr>
</tbody>
</table>
<pre><code class="R">source('https://bioconductor.org/biocLite.R')
biocLite('dada2')
biocLite('phyloseq')
biocLite('DECIPHER')
install.packages('ggplot2')
install.packages('phangorn')
</code></pre>

<ul>
<li>load the packages and verify you have the correct DADA2 version</li>
</ul>
<pre><code class="R">library(dada2)
library(ggplot2)
library(phyloseq)
library(phangorn)
library(DECIPHER)
packageVersion('dada2')
</code></pre>

<ul>
<li>downloaded our data in shell</li>
</ul>
<pre><code class="bash">wget http://www.mothur.org/w/images/d/d6/MiSeqSOPData.zip
unzip MiSeqSOPData.zip
cd MiSeq_SOP
wget https://zenodo.org/record/824551/files/silva_nr_v128_train_set.fa.gz
wget https://zenodo.org/record/824551/files/silva_species_assignment_v128.fa.gz
</code></pre>

<ul>
<li>Assign in R the path to our data to a variable and check it</li>
</ul>
<pre><code class="R">path &lt;- '~/MiSeq_SOP'
list.files(path)
</code></pre>

<h3 id="2-filtering-and-trimming-the-reads-in-r-using-dada2">2. Filtering and Trimming the Reads in R using DADA2</h3>
<ul>
<li>create two lists with the sorted name of the reads: one for forward reads, one for reverse reads</li>
</ul>
<pre><code class="R">raw_forward &lt;- sort(list.files(path, pattern=&quot;_R1_001.fastq&quot;, full.names=TRUE))
raw_reverse &lt;- sort(list.files(path, pattern=&quot;_R2_001.fastq&quot;, full.names=TRUE))
# we also need the sample names
sample_names &lt;- sapply(strsplit(basename(raw_forward), &quot;_&quot;), `[`, 1)
</code></pre>

<ul>
<li>visualising the quality of our reads</li>
</ul>
<pre><code class="R">plotQualityProfile(raw_forward[1:2])
plotQualityProfile(raw_reverse[1:2])
</code></pre>

<blockquote>
<p>The quality plots (for reverse) are looking like this:
<img alt="" src="https://i.imgur.com/YWzTV1o.png" />
really bad quality starting at around 150 bp</p>
</blockquote>
<ul>
<li>Dada2 requires us to define the name of our output files first before trimming</li>
</ul>
<pre><code class="R"># place filtered files in filtered/ subdirectory
filtered_path &lt;- file.path(path, &quot;filtered&quot;)
filtered_forward &lt;- file.path(filtered_path, paste0(sample_names, &quot;_R1_trimmed.fastq.gz&quot;))
filtered_reverse &lt;- file.path(filtered_path, paste0(sample_names, &quot;_R2_trimmed.fastq.gz&quot;))
</code></pre>

<ul>
<li>for filtering parameters: <code>maxN=0</code> (DADA2 requires no Ns), <code>truncQ=2</code>, <code>rm.phix=TRUE</code> and <code>maxEE=2</code></li>
<li>maxEE parameter sets the maximum number of “expected errors
allowed in a read, which <a href="http://www.drive5.com/usearch/manual/expected_errors.html">according to the USEARCH authors</a> is a better filter than simply averaging quality scores</li>
</ul>
<pre><code class="R">out &lt;- filterAndTrim(raw_forward, filtered_forward, raw_reverse, filtered_reverse, truncLen=c(240,160), maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE, compress=TRUE, multithread=TRUE)
head(out) #to see the read output
</code></pre>

<ul>
<li>DADA2 algorithm depends on a parametric error model and every amplicon dataset has a slightly different error rate</li>
<li><code>learnErrors</code> of DADA2 learns the error model from the data and will help DADA2 to fits its method to your data</li>
</ul>
<pre><code class="R">errors_forward &lt;- learnErrors(filtered_forward, multithread=TRUE)
errors_reverse &lt;- learnErrors(filtered_reverse, multithread=TRUE)
</code></pre>

<ul>
<li>visualise the estimated error rates</li>
</ul>
<pre><code>plotErrors(errors_forward, nominalQ=TRUE) + theme_minimal()
</code></pre>

<blockquote>
<p>The error rates for each possible transition (eg. A to C, A to G (A2G), …) are shown:
<img alt="" src="https://i.imgur.com/37JZKgU.png" /></p>
</blockquote>
<h3 id="3-dereplication">3. Dereplication</h3>
<ul>
<li><strong>Dereplication</strong> combines identical reads into "unique sequences" with a corresponding "abundance" (number of reads with that unique sequence)</li>
<li>highly reduces computation time by eliminating redundant comparisons</li>
</ul>
<pre><code class="R">derep_forward &lt;- derepFastq(filtered_forward, verbose=TRUE)
derep_reverse &lt;- derepFastq(filtered_reverse, verbose=TRUE)
# name the derep-class objects by the sample names
names(derep_forward) &lt;- sample_names
names(derep_reverse) &lt;- sample_names
</code></pre>

<h3 id="4-sample-inference">4. Sample inference</h3>
<ul>
<li>appling the core sequence-variant inference algorithm to the dereplicated data</li>
</ul>
<pre><code class="R">dada_forward &lt;- dada(derep_forward, err=errors_forward, multithread=TRUE)
dada_reverse &lt;- dada(derep_reverse, err=errors_reverse, multithread=TRUE)
# inspect the dada-class object
dada_forward[[1]]
</code></pre>

<h3 id="5-merge-paired-end-reads">5. Merge Paired-end Reads</h3>
<ul>
<li>reads are now trimmed, dereplicated and error-corrected, so we merge R1 &amp; R2 together</li>
</ul>
<pre><code class="R">merged_reads &lt;- mergePairs(dada_forward, derep_forward, dada_reverse, derep_reverse, verbose=TRUE)
# inspect the merger data.frame from the first sample
head(merged_reads[[1]])
</code></pre>

<h3 id="6-construct-sequence-table">6. Construct Sequence Table</h3>
<ul>
<li>constructing a sequence table of our samples</li>
<li>a higher-resolution version of the OTU table produced by traditional methods</li>
</ul>
<pre><code class="R">seq_table &lt;- makeSequenceTable(merged_reads)
dim(seq_table)
# inspect distribution of sequence lengths
table(nchar(getSequences(seq_table)))
</code></pre>

<h3 id="7-remove-chimeras">7. Remove Chimeras</h3>
<ul>
<li>this are reads who map to more than one region or contig (so called split-reads)</li>
<li><code>dada</code> removes substitutions and indel errors but chimeras remain</li>
<li>We remove the chimeras with:</li>
</ul>
<pre><code class="R">seq_table_nochim &lt;- removeBimeraDenovo(seq_table, method='consensus', multithread=TRUE, verbose=TRUE)
dim(seq_table_nochim)
# which percentage of our reads did we keep?
sum(seq_table_nochim) / sum(seq_table)
</code></pre>

<ul>
<li>as a final check of our progress, we’ll look at the number of reads that made it through each step in the pipeline:</li>
</ul>
<pre><code class="R">get_n &lt;- function(x) sum(getUniques(x))
track &lt;- cbind(out, sapply(dada_forward, get_n), sapply(merged_reads, get_n), rowSums(seq_table), rowSums(seq_table_nochim))
colnames(track) &lt;- c('input', 'filtered', 'denoised', 'merged', 'tabled', 'nonchim')
rownames(track) &lt;- sample_names
head(track) #checking the table we build

##Looks like this:
##        input filtered denoised merged tabled nonchim
## F3D0    7793     7113     7113   6600   6600    6588
## F3D1    5869     5299     5299   5078   5078    5067
</code></pre>

<h3 id="8-assign-taxonomy">8. Assign Taxonomy</h3>
<ul>
<li>now we assign taxonomy to our sequences using the <strong>SILVA database</strong></li>
</ul>
<pre><code class="R">taxa &lt;- assignTaxonomy(seq_table_nochim, '~/MiSeq_SOP/silva_nr_v128_train_set.fa.gz', multithread=TRUE)
taxa &lt;- addSpecies(taxa, '~/MiSeq_SOP/silva_species_assignment_v128.fa.gz')
</code></pre>

<ul>
<li>inspecting the classification with:</li>
</ul>
<pre><code class="R">taxa_print &lt;- taxa  # removing sequence rownames for display only
rownames(taxa_print) &lt;- NULL
head(taxa_print)
</code></pre>

<h3 id="9-phylogenetic-tree">9. Phylogenetic Tree</h3>
<ul>
<li>creating a multiple alignment</li>
</ul>
<pre><code class="R">sequences &lt;- getSequences(seq_table)
names(sequences) &lt;- sequences  # this propagates to the tip labels of the tree
alignment &lt;- AlignSeqs(DNAStringSet(sequences), anchor=NA)
</code></pre>

<ul>
<li>build a neighbour-joining tree then fit a maximum likelihood tree using the neighbour-joining tree as a starting point</li>
</ul>
<pre><code class="R">phang_align &lt;- phyDat(as(alignment, 'matrix'), type='DNA')
dm &lt;- dist.ml(phang_align)
treeNJ &lt;- NJ(dm)  # note, tip order != sequence order
fit = pml(treeNJ, data=phang_align) #changed negative lengths to 0

fitGTR &lt;- update(fit, k=4, inv=0.2)
fitGTR &lt;- optim.pml(fitGTR, model='GTR', optInv=TRUE, optGamma=TRUE, rearrangement = 'stochastic', control = pml.control(trace = 0))
detach('package:phangorn', unload=TRUE)
</code></pre>

<h3 id="10-phyloseq">10. Phyloseq</h3>
<ul>
<li>we load now pre-prepared meta data for this tutorial</li>
<li>its a normal tab table or data.frame starting with the sequence name</li>
</ul>
<pre><code class="R">sample_data &lt;- read.table('https://hadrieng.github.io/tutorials/data/16S_metadata.txt', header=TRUE, row.names=&quot;sample_name&quot;)
</code></pre>

<ul>
<li>constructing the phyloseq object using our output and the downloaded metadata</li>
<li>we remove the mock sample, which is some kind of quality control of the whole process (it consists of 20 samples of known connetions)</li>
<li>for more details about the mock sample look at the <a href="https://benjjneb.github.io/dada2/tutorial.html">extensive tutorial</a></li>
</ul>
<pre><code class="R">physeq &lt;- phyloseq(otu_table(seq_table_nochim, taxa_are_rows=FALSE), sample_data(sample_data), tax_table(taxa), phy_tree(fitGTR$tree))
# remove mock sample
physeq &lt;- prune_samples(sample_names(physeq) != 'Mock', physeq)
physeq
</code></pre>

<h3 id="11-diversity-analysis-graphs">11. Diversity analysis graphs</h3>
<h4 id="diversity">α diversity</h4>
<ul>
<li><code>plot_richness</code> is from <code>phyloseq package</code>. its just a "wrapper" so no calculations. We use the Shannon and Fisher wraper.</li>
</ul>
<pre><code class="R">plot_richness(physeq, x='day', measures=c('Shannon', 'Fisher'), color='when') + theme_minimal()
</code></pre>

<p><img alt="" src="https://i.imgur.com/eiBIXKb.png" /></p>
<hr />
<h4 id="diversity_1">β diversity</h4>
<p><strong>1. Performed a MDS with euclidean distance (mathematically equivalent to a PCA)</strong></p>
<pre><code class="R">ord &lt;- ordinate(physeq, 'MDS', 'euclidean')
plot_ordination(physeq, ord, type='samples', color='when', title='PCA of the samples from the MiSeq SOP') + theme_minimal()
</code></pre>

<p><img alt="" src="https://i.imgur.com/jIxxBFF.png" />
<strong>2. Performed with Bray-Curtis distance</strong></p>
<pre><code class="R">ord &lt;- ordinate(physeq, 'NMDS', 'bray')
plot_ordination(physeq, ord, type='samples', color='when', title='PCA of the samples from the MiSeq SOP') + theme_minimal()
</code></pre>

<ul>
<li>beta diversity (Bray-Courtis distance) looks like this:</li>
</ul>
<p><img alt="" src="https://i.imgur.com/Ha5ogZY.png" /></p>
<hr />
<p><strong>Distribution of the most abundant families</strong></p>
<pre><code class="R">top20 &lt;- names(sort(taxa_sums(physeq), decreasing=TRUE))[1:20]
physeq_top20 &lt;- transform_sample_counts(physeq, function(OTU) OTU/sum(OTU))
physeq_top20 &lt;- prune_taxa(top20, physeq_top20)
plot_bar(physeq_top20, x='day', fill='Family') + facet_wrap(~when, scales='free_x') + theme_minimal()
</code></pre>

<ul>
<li>looks like this
<img alt="" src="https://i.imgur.com/SbFTCTD.png" /></li>
</ul>
<hr />
<p>We can place them in a tree</p>
<pre><code class="R">bacteroidetes &lt;- subset_taxa(physeq, Phylum %in% c('Bacteroidetes'))
plot_tree(bacteroidetes, ladderize='left', size='abundance', color='when', label.tips='Family')
</code></pre>

<p>Looks like this:
<img alt="" src="https://i.imgur.com/K2YvCIF.png" /></p>
<h1 id="10-ugene">10 - UGENE</h1>
<ul>
<li><a href="http://ugene.net/">UGENE</a> is free open-source cross-platform bioinformatics software</li>
<li>It works perfectly on Windows, Mac OS and Linux</li>
</ul>
<p>Install commands for Linux:</p>
<pre><code class="bash">sudo add-apt-repository ppa:iefremov/ppa
sudo apt-get update
sudo apt-get install ugene
sudo apt-get install ugene-non-free
</code></pre>

<p>Download all dependencies for linux <strong>ready to go</strong> <a href="http://ugene.net/external.html">from here</a>
Online Tutorial can be <a href="https://ugene.net/wiki/pages/viewpage.action?pageId=2523429">found here</a></p>
<ol>
<li><a href="https://www.youtube.com/watch?v=2pZszPGKnT8">Multiple sequence alignment</a></li>
<li><a href="https://www.youtube.com/watch?v=R09CIWyDSQk">basic sequence operations part 1</a></li>
<li><a href="https://www.youtube.com/watch?v=lD2JqfxKlk0">Working with multiple sequence alignments</a></li>
<li><a href="https://www.youtube.com/watch?v=vUinIZsWPJI">Creating annotations</a></li>
<li><a href="https://www.youtube.com/watch?v=fSjCAtIETfA">Annotation qualifiers</a></li>
<li><a href="https://www.youtube.com/watch?v=i2YqOza6Kyo">Querying remote database</a></li>
<li><a href="https://www.youtube.com/watch?v=J5Xj84yeL9M">3D Structure viewer</a> , <a href="https://www.youtube.com/watch?v=ZG2twNSv0-M">multiple structure view and image export</a></li>
<li><a href="https://www.youtube.com/watch?v=M3D0YrGshns">local sequence alignment with Smith-Waterman algorithm</a></li>
<li><a href="https://www.youtube.com/watch?v=sl-_3IcPHTI">Restriction enzymes</a></li>
<li><a href="https://www.youtube.com/watch?v=npN1mZoK4lE">Large alignments</a></li>
<li><a href="https://www.youtube.com/watch?v=ArEtX9IAyt4">Open Reading Frames</a></li>
<li><a href="https://www.youtube.com/watch?v=9a1wvynLWBo">Chromatograms viewer and editor</a></li>
<li><a href="https://www.youtube.com/watch?v=RaH0HqYcDAQ">Finding DNA repeats</a></li>
<li><a href="https://www.youtube.com/watch?v=MC0Frw8TSDA">Searching for homologs of protein sequence with HMMMER3</a></li>
<li><a href="https://www.youtube.com/watch?v=w0rQ1sa1ajU">Finding DNA tandem repeats</a></li>
<li><a href="https://www.youtube.com/watch?v=YWV056ddOB4">Compare sequences with dotplots</a></li>
<li><a href="https://www.youtube.com/watch?v=EEk3cXiLFOk">Alignment Editor</a></li>
<li><a href="https://www.youtube.com/watch?v=Ad-HCdo5flo">Phylogenetic trees algorithms</a></li>
<li><a href="https://www.youtube.com/watch?v=HgJrOJzCb68&amp;noredirect=1">Transcription binding sites</a></li>
<li><a href="https://www.youtube.com/watch?v=AYECTzDuibg">Profile-to-profile and profile-to-sequence MUSCLE alignments</a></li>
<li><a href="https://www.youtube.com/watch?v=s5zp8DZxNVI">Workflow Designer</a></li>
</ol>
<h1 id="11-epigenetics">11 - Epigenetics</h1>
<h2 id="overview_2">Overview</h2>
<ul>
<li><strong>Epigenetics</strong> is the study of heritable changes in gene function that do not involve changes in the DNA sequence</li>
<li>is influenced by age, environment, life style, diseases</li>
<li>these modifications can be heritable</li>
<li>not all genes are active at all times</li>
<li>there are five histone families (Linker Histones: H1/H5 and Core Histones: H2A, H2B, H3 and H4)
<img alt="" src="http://wondergressive.com/wp-content/uploads/2013/12/rvx_epigenetics.jpg" /></li>
</ul>
<h3 id="reduced-representation-bisulfite-sequencing-rrbs">Reduced representation bisulfite sequencing (RRBS)</h3>
<ul>
<li>is an efficient and high-throughput technique used to analyze the genome-wide <a href="https://en.wikipedia.org/wiki/Methylation" title="Methylation">methylation</a> profiles on a single nucleotide level</li>
<li><a href="https://en.wikipedia.org/wiki/Reduced_representation_bisulfite_sequencing">RRBS</a> combines restriction enzymes and <a href="https://en.wikipedia.org/wiki/Bisulfite_sequencing" title="Bisulfite sequencing">bisulfite sequencing</a> in order to enrich for the areas of the genome that have a high <a href="https://en.wikipedia.org/wiki/CpG_site" title="CpG site">CpG</a> content.</li>
<li>bisulfite threatment basically converts non methylated C's into T's so you can compare and see what has changed
<img alt="" src="https://upload.wikimedia.org/wikipedia/commons/thumb/f/ff/Reduced_Representation_Bisulfite_Sequencing_Protocol.jpg/800px-Reduced_Representation_Bisulfite_Sequencing_Protocol.jpg" /></li>
</ul>
<h1 id="12-genome-annotation">12 - Genome annotation</h1>
<h2 id="structural-genome-annotation">Structural genome annotation</h2>
<ul>
<li><strong>Structural</strong> gene annotation - find out where the region of interest is</li>
<li><strong>Functional</strong> gene annotation - find out what the region do</li>
<li>gff - genome feature file</li>
</ul>
<p><strong>Main steps:</strong>
QC assembly -&gt; structural annotation -&gt; manual curation -&gt; functional annotation -&gt; Submission or Downstream analysis
<em> QC of assembly is highly important
</em> Repeat Masking to improve the gene annotations
<em> most pipelines have this included, but check first before using a annotation program
</em> annotations are either based on proteins or transcripts
<em> if a protein is unknown then you won't annotate it
</em> RNA-seq tries to find all transcripts - should always be included in a annotation project</p>
<p><strong>Approaches for annotations:</strong>
<em> </em>Similarity-based methods<em> - these use similarity to annotated sequences like proteins, cDNAs, or ESTs
</em> <em>Ab initio prediction</em> - likelihood based methods that needs to be trained (give them 1000 known genes of a species)
    * annotations based on gene content (codon usage, GC content, exon/intron size, promotor, ORF, start codons, splice sites and more)
    * sensitivity and specifity has to be determined after the training
    * false positive results? overpredicting?
    * sensitivity and specifity on nucleotide level is more important than on gene level when evaluating the performance
<em> </em>Hybrid approaches<em> - ab </em>initio<em> tools with the ability to integrate external evidence/hints
</em> <em>Comparative (homology) based gene finders</em> - these align genomic sequences from different species and use the alignments to  guide the gene predictions
<em> </em>Chooser, combiner approaches<em> - these combine gene predictions of other gene finders
</em> <em>Pipelines</em> - These combine multiple approaches
    * use a pipeline</p>
<blockquote>
<p><strong>Popular tools</strong>:
[color=lightblue]</p>
<blockquote>
<p><strong>Supported by the maker tool:</strong>
[color=orange]
<em> <strong>SNAP</strong> - Works ok, easy to train, not as good as others especially on longer intron genomes.
</em> <strong>Augustus</strong> - Works great, hard to train (but getting better)
<em> <strong>GeneMark-ES</strong> - Self training, no hints, buggy, not good for fragmented genomes or long introns (Best suited for Fungi).
</em> <strong>FGENESH</strong> - Works great, costs money even for training.
<em> <strong>GlimmerHMM (Eukaryote)</strong>
</em> <strong>GenScan</strong>
* <strong>Gnomon (NCBI)</strong></p>
</blockquote>
</blockquote>
<ul>
<li>but you want to use those tools in a pipeline - combining various methodes since it improves highly the output quality</li>
</ul>
<blockquote>
<p><strong>PIPELINES</strong>:
[color=lightblue]</p>
<blockquote>
<p><strong>PASA</strong>
[color=orange]
<em> Produces evidence-driven consensus gene models
</em> (-) minimalist pipeline
<em> (+) good for detecting isoforms
</em> (+) biologically relevant predictions
<em> using Ab initio tools and combined with EVM it does a pretty good job
</em> PASA + Ab initio + EVM is not automatized</p>
<p><strong>NCBI pipeline</strong>
[color=lightgreen]
<em> best one yet - but difficult to install
</em> NCBI staff can be asked an they help you
* Evidence + ab initio (Gnomon), repeat masking, gene naming, data formatting, miRNAs, tRNAs</p>
<p><strong>Ensembl</strong>
[color=orange]
* Evidence based only ( comparative + homology )</p>
<p><strong>MAKER2</strong>
[color=lightgreen]
<em> Evidence based and/or ab initio
</em> developed as an easy-to-use alternative to other pipelines
<em> Easy to use and to configure
</em> Almost unlimited parallelism built-in (limited by data and hardware)
<em> Largely independent from the underlying system it is run on
</em> Everything is run through one command, no manual combining of data/outputs
<em> Follows common standards, produces GMOD compliant output
</em> Annotation Edit Distance (AED) metric for improved quality control
<em> Provides a mechanism to train and retrain ab </em>initio<em> gene predictors
</em> Annotations can be updated by re-launching Maker with new evidence</p>
</blockquote>
</blockquote>
<ul>
<li>Pipelines give good results, MAKER2 the most flexible, adjustable</li>
<li>Most methods only build gene models, no functional inference</li>
<li>Computational pipelines make mistakes</li>
<li>Annotation requires manual curation</li>
<li>As for assembly, an annotation is never finished, it can always be improved (e.g. Human)</li>
</ul>
<h2 id="genome-annotation-with-augustus-practical">Genome annotation with <code>augustus</code> - practical</h2>
<ul>
<li>we are using chromosome 4 of the fruit fly, Drosophila melanogaster</li>
<li>QC of the assembly first:<ul>
<li>Fragmentation? (N50, N90, how many short contigs)</li>
<li>Sanity of the fasta file (Presence of Ns, presence of ambiguous nucleotides, presence of lowercase nucleotides, single line sequences vs multiline sequences)</li>
<li>completeness (using BUSCO)</li>
<li>presence of organelles</li>
<li>Others (GC content, How distant the investigated species is from the others annotated species available)</li>
</ul>
</li>
</ul>
<h3 id="1-busco-for-assembly-check">1. <code>BUSCO</code> for Assembly check</h3>
<ul>
<li>BUSCO provides quantitative measures for the assessment of genome assembly, gene set, and transcriptome completeness, based on evolutionarily-informed expectations of gene content from near-universal single-copy orthologs selected from <a href="http://orthodb.org">OrthoDB <em>v9</em></a>.</li>
<li>first get the best dataset from the <a href="http://busco.ezlab.org">busco website</a></li>
</ul>
<pre><code class="bash">wget http://busco.ezlab.org/datasets/metazoa_odb9.tar.gz
tar xzvf metazoa_odb9.tar.gz
</code></pre>

<ul>
<li>launching BUSCO, to create the folder 4_dmel_busco</li>
<li>inside is a <code>short_summary_4_dmel_busco.txt</code> for statistics on how many genes/regions could be found in comparision to the reference genome</li>
<li>the better the assembly the more will be found</li>
</ul>
<pre><code class="bash">BUSCO.py -i ~/annotation_course/data/genome/4.fa -o 4_dmel_busco -m geno -c 8 -l metazoa_odb9
</code></pre>

<ul>
<li><code>fasta_statisticsAndPlot.pl</code> is  used for additional statistics</li>
<li>Part of this <a href="https://github.com/NBISweden/GAAS/commit/74fb7049b47f4816ecfd7fdffaa4a622831e80a2">github rep called GAAS</a></li>
</ul>
<pre><code>fasta_statisticsAndPlot.pl -f ~/annotation_course/data/genome/4.fa
</code></pre>

<h3 id="2-augustus-an-ab-initio-gene-finder">2. <code>augustus</code> an ab <em>initio</em> gene finder</h3>
<ul>
<li>if satisfied by the quality of the assembly we start the annotation</li>
<li>we focus on the gene finder <code>augustus</code></li>
<li>these gene finders use likelihoods to find the most likely genes in the genome</li>
<li>they are aware of start and stop codons and splice sites, and will only try to predict genes that follow these rules</li>
<li>the most important factor here is that the gene finder needs to be trained on the organism you are running the program on, otherwise the probabilities for introns, exons, etc. will not be correct</li>
<li>we have training files for Drosophila</li>
</ul>
<p><strong>Augustus</strong>
* call it with a genome/assembly and it saves the annotation as a gff3 file</p>
<pre><code class="bash">augustus --species=fly ~/annotation_course/data/genome/4.fa --gff3=yes &gt; augustus_drosophila.gff
#to get additional isoforms use this:
augustus --species=fly ~/annotation_course/data/genome/4.fa --gff3=yes --alternatives-from-sampling=true &gt; augustus_drosophila_isoform.gff
</code></pre>

<ul>
<li><code>gff3_sp_statistics.pl</code> is also from GAAS for the created gff file from <code>augustus</code></li>
<li>gives an statistical overview of the gene annotations</li>
</ul>
<pre><code>gff3_sp_statistics.pl --gff augustus_drosophila.gff
</code></pre>

<h3 id="3-visualisation">3. Visualisation</h3>
<ul>
<li>opened the chromosome 4 file and the gff file in UGENE</li>
<li>looks like this:
<img alt="" src="https://i.imgur.com/rAxyelb.png" /></li>
<li>An other good and popular software to explore genomes is <a href="https://software.broadinstitute.org/software/igv/">IGV</a></li>
</ul>
<h2 id="running-the-maker-gene-build-pipeline-practical">Running the <code>maker</code> gene build pipeline - practical</h2>
<p><strong>MAKER</strong> is a computational pipeline to automatically generate annotations from a range of input data. The Maker pipeline can work with any combination of the following data sets, which are put into the <code>maker_opts.ctl</code>:</p>
<ul>
<li>Proteins from the same species or related<ul>
<li>Swissport for high quality protein sequences</li>
<li>Refseq sequence sets from the <a href="ftp://ftp.ncbi.nlm.nih.gov/refseq/">ftp-servers</a></li>
<li>Ensembl using Biomart interface to download data for a specific region or a specific gene</li>
</ul>
</li>
<li>Proteins from more distantly related organisms<ul>
<li>Uniprot to include protein sequences from organisms closely related to your study organism</li>
</ul>
</li>
<li>EST sequences from the same species or very closely related species<ul>
<li>NCBI or EBI websites to retrieve such kind of data  </li>
</ul>
</li>
<li>RNA-seq data from the same or very closely related species, in the form of splice sites or assembled transcripts<ul>
<li>normally genereted by yourself or are retrived on the Sequence Read Archive of NCBI (SRA) or the ENA of EBI</li>
</ul>
</li>
<li>ab <em>initio</em> predictions from one or more tools (supported are: Augustus, Snap, GeneMark, Fgenesh)</li>
</ul>
<h3 id="1-start-maker">1. Start <code>maker</code></h3>
<ul>
<li>do <code>maker -CTL</code> to create the 3 files for the pipeline (<code>maker_opts.ctl, maker_bopts.ctl, maker_exe.ctl</code>)</li>
</ul>
<h3 id="21-evidence-based-annotation">2.1 Evidence-based annotation</h3>
<ul>
<li>the best protein- and EST-alignments are chosen to build the most likely gene model, <strong>without an ab <em>initio</em> model</strong></li>
</ul>
<blockquote>
<p>We need to prepare various files and add their path to the <code>maker_opts.ctl</code> file (use , to seperate files):
<em>   name of the genome sequence (<code>genome=</code>)
</em>   name of the 'EST' set file(s) (<code>est=</code>)
<em>   name of the 'Protein' set file(s) (<code>protein=</code>)
</em>   name of the repeatmasker and repeatrunner files (<code>rm_gff=</code>)
<em> disabling ab </em>initio<em> with <code>protein2genome=1</code>, <code>est2genome=1</code>
</em> we deactivated the parameters <code>model_org=</code> and <code>repeat_protein=</code> to avoid the heavy work of repeatmasker (blank values)</p>
</blockquote>
<ul>
<li>if the <code>maker_opts.ctl</code>is configured properly start the maker pipeline with</li>
</ul>
<pre><code class="bash">mpiexec -n 8 maker # -n is core numbers
# and compile the output with:
maker_merge_outputs_from_datastore.pl --output maker_no_abinitio
</code></pre>

<ul>
<li>in the folder you find the annotation file <code>maker.gff</code></li>
<li>to get statistics use the <code>gff3_sp_statistics.pl</code></li>
</ul>
<pre><code>gff3_sp_statistics.pl --gff maker_no_abinitio/annotationByType/maker.gff
</code></pre>

<h3 id="22-run-maker-with-ab-initio-predictions">2.2 Run Maker with ab-initio predictions</h3>
<ul>
<li>instead of step 2.2 builds on the gff from step 2.1 and does a ab-initio prediction</li>
<li>These files were present(repeatmasker.chr4.gff, repeatrunner.chr4.gff, 4.fa)</li>
<li>These were created in Step 2.1 (est_gff_stringtie.gff, est2genome.gff, protein2genome.gff)</li>
<li>so add them to the <code>maker_opts.ctl</code></li>
<li>change these now to <code>protein2genome=0</code>, <code>est2genome=0</code>, <code>keep_preds=1</code>, <code>augustus_species=fly</code></li>
<li>With these settings, Maker will run augustus to predict gene loci, but inform these predictions with information from the protein and est alignments</li>
<li><strong>You can combine step 2.1 &amp; 2.2 into one</strong></li>
<li><strong>its basically step 2.1 with augustus and ab initio activated (the gffs are created during the pipeline)</strong></li>
</ul>
<pre><code class="bash">mpiexec -n 8 maker
#compiling
maker_merge_outputs_from_datastore.pl --output maker_with_abinitio
#check statistics with this GAAS script
gff3_sp_statistics.pl --gff maker_with_abinitio/annotationByType/maker.gff
</code></pre>

<p><strong>Summary</strong>: We created 2 maker.gff files. One in <code>maker_with_abinto/</code> one in <code>maker_noabinto directory/</code>. Doing Step 2.2 helped to make the gene predictions less fragmented. For best performance go all th way to step 2.2.</p>
<blockquote>
<p>For Intron / Exon manual curation look for the GT/AG in an Intron
5'-3' [EXON]++GT--intron--AG++[EXON]
3'-5' [EXON]++GA--intron--TG++[EXON]
<img alt="" src="http://slideplayer.com/10370846/35/images/1/Schematic+of+Eukaryotic+Protein-Coding+Locus.jpg" /></p>
</blockquote>
<h2 id="functional-genome-annotation">Functional genome annotation</h2>
<ul>
<li><strong>Functional</strong> gene annotation - find out what the region does</li>
<li>You can do this experimentally (slow and expensive) or computationally</li>
</ul>
<p><strong>Computationally:</strong>
<em> Sequence based - ==mainly done==
    * based on similarity/motif/profile
    * orthology based on evolutionary relationship
        * Clustering with KOG/COG
        * Synteny: Satsuma + kraken + custom script
        * phylogeny based
</em> Structure based
    * global structure comparison
    * localized regions
    * active sites resides
* Protein-Protein Interaction data</p>
<h3 id="blast-based-functional-genome-annotation">blast based functional genome annotation</h3>
<ul>
<li>you need Sequence, gff3 files</li>
<li>Uniprot (exhaustive) or Swissprot (reliable)</li>
<li>Use Annie to extract best hits from blast-hit list and the corresponding description from uniprot-headers</li>
<li>Add the information to the annotation.gff using custom-script</li>
<li>then you have a nice description of the blast hit in the gff file</li>
</ul>
<table>
<thead>
<tr>
<th>Database</th>
<th>Information</th>
<th>Comment</th>
</tr>
</thead>
<tbody>
<tr>
<td>KEGG</td>
<td>Pathway</td>
<td>Kyoto Encyclopedia of Genes and Genomes</td>
</tr>
<tr>
<td>MetaCyc</td>
<td>Pathway</td>
<td>Curated database of experimentally elucidated metabolic pathways from all domains of life (NIH)</td>
</tr>
<tr>
<td>Reactome</td>
<td>Pathway</td>
<td>Curated and peer reviewed pathway database</td>
</tr>
<tr>
<td>UniPathway</td>
<td>Pathway</td>
<td>Manually curated resource of enzyme-catalyzed and spontaneous chemical reactions.</td>
</tr>
<tr>
<td>GO</td>
<td>Gene Ontology</td>
<td>Three structured, controlled vocabularies (ontologies) : biological processes, cellular components and molecular functions</td>
</tr>
<tr>
<td>Pfam</td>
<td>Protein families</td>
<td>Multiple sequence alignments and hidden Markov models</td>
</tr>
<tr>
<td>Interpro</td>
<td>P. fam., domains &amp; functional sites</td>
<td>Run separate search applications, and create a signature to search against Interpro.</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>Tool</th>
<th>Approach</th>
<th>Comment</th>
</tr>
</thead>
<tbody>
<tr>
<td>Trinotate</td>
<td>Best blast hit, protein domain identification (HMMER/PFAM), protein signal peptide and transmembrane domain prediction (signalP/tmHMM), and leveraging various annotation databases (eggNOG/GO/Kegg databases).</td>
<td>Not automated</td>
</tr>
<tr>
<td>Annocript</td>
<td>Best blast hit</td>
<td>Collects the best-hit and related annotations (proteins, domains, GO terms, Enzymes, pathways, short)</td>
</tr>
<tr>
<td>Annot8r</td>
<td>Best blast hits</td>
<td>A tool for Gene Ontology, KEGG biochemical pathways and Enzyme Commission EC number annotation of nucleotide and peptide sequences.</td>
</tr>
<tr>
<td>Sma3s</td>
<td>Best blast hit, Best reciprocal blast hit, clusterisation</td>
<td>3 annotation levels</td>
</tr>
<tr>
<td>afterParty</td>
<td>BLAST, InterProScan</td>
<td>web application</td>
</tr>
<tr>
<td>==<strong>Interproscan</strong>==</td>
<td>Separate search applications, HMMs, fingerprints, patterns of InterPro</td>
<td>Created to unite secondary databases</td>
</tr>
<tr>
<td>Blast2Go</td>
<td>get best blast hits</td>
<td>Retrieve only GO,Commercial !</td>
</tr>
</tbody>
</table>
<h2 id="interproscan-approach-practical">Interproscan approach - practical</h2>
<ul>
<li>we took a gff file and the corresponding fasta file</li>
<li>we had a pre downloaded database</li>
<li>we used this script to extract the protein sequences with an gff annotation (<code>AA.fa</code>)</li>
</ul>
<pre><code class="bash">gff3_sp_extract_sequences.pl --gff maker_with_abinitio.gff -f 4.fa -p --cfs -o AA.fa
</code></pre>

<ul>
<li>we used the <a href="https://github.com/ebi-pf-team/interproscan/wiki/HowToDownload">interproscan</a> complete thing - incl. databases (48 GB) to get the information</li>
<li>there is a way to analyse through the web but it has a limit on requests</li>
</ul>
<pre><code class="bash">#takes 2-3 seconds per protein
interproscan.sh -i AA.fa -t p -dp -pa -appl Pfam,ProDom-2006.1,SuperFamily-1.75 --goterms --iprlookup
</code></pre>

<ul>
<li>load the retrieved functional information in your annotation file writing your own script or use the<code>maker</code> script</li>
</ul>
<pre><code class="bash">ipr_update_gff maker_with_abinitio.gff AA.fa.tsv &gt;  maker_with_abinitio_with_interpro.gff
</code></pre>

<h2 id="blast-approach-practical">BLAST approach - practical</h2>
<ul>
<li>similar to your resistance gene blasts</li>
</ul>
<pre><code class="bash">blastp -db ~/annotation_course/data/blastdb/uniprot_dmel/uniprot_dmel.fa -query AA.fa -outfmt 6 -out blast.out -num_threads 8
</code></pre>

<ul>
<li>we are using <code>annie</code> to process the blast output</li>
</ul>
<pre><code class="bash">git clone https://github.com/genomeannotation/Annie.git
# This is the annie.py script
Annie/annie.py -b blast.out -db ~/annotation_course/data/blastdb/uniprot_dmel/uniprot_dmel.fa -g maker_with_abinitio.gff -o annotation_blast.annie
</code></pre>

<ul>
<li>
<p>Annie writes in a 3-column table format file, providing gene name and mRNA product information. The purpose of annie is relatively simple. It recovers the information in the sequence header of the uniprot fasta file, from the best sequence found by Blast (the lowest e-value).</p>
</li>
<li>
<p>load the retrieved functional information in your annotation file writing your own script or use the<code>maker</code> script</p>
</li>
</ul>
<pre><code>maker_gff3manager_JD_v8.pl -f maker_with_abinitio_with_interpro.gff -b annotation_blast.annie --ID FLY -o finalOutputDir
</code></pre>

<ul>
<li>we change the [product] tag to the [description] tag so Webapollo shows the actual protein name directly in the screen instead of just hovering over it</li>
</ul>
<pre><code>/home/student/.local/GAAS/annotation/WebApollo/gff3_webApollo_compliant.pl --gff finalOutputDir/codingGeneFeatures.gff -o final_annotation.gff
</code></pre>

<h3 id="subbmitting-to-ebi-using-a-tool">Subbmitting to EBI using a tool</h3>
<p>In order to submit to <strong>EBI</strong>, the use of a tool like <a href="https://github.com/NBISweden/EMBLmyGFF3">EMBLmyGFF3</a> will be your best choice.</p>
<p><strong>Let's prepare your annotation to submit to ENA (EBI)</strong>
You need to create an account and create a project asking a locus_tag for your annotation. You have  to fill lot of metada information related to the assembly and so on. We will skip those tasks using fake information. First you need to download and install EMBLmyGFF3:</p>
<pre><code>pip install --user git+https://github.com/NBISweden/EMBLmyGFF3.git
EMBLmyGFF3 finalOutputDir/codingGeneFeatures.gff 4.fa -o my_annotation_ready_to_submit.embl
</code></pre>

<p>You now have a EMBL flat file ready to submit.</p>
<h1 id="13-other-useful-informations">13 - Other useful informations</h1>
<ul>
<li>Lots of bioinformatic tools developed in sweden, check <a href="https://nbis.se/infrastructure/tools/">this site</a></li>
<li>more stuff for <a href="https://sgbc.github.io/course/nbis_annotation/practical_session/practical2_sub_transcriptome/">RNAseq</a></li>
</ul>
<h2 id="uppmax-cloud">UPPMAX Cloud</h2>
<h3 id="what-is-it">What is it?</h3>
<ul>
<li><strong>Rackham</strong>: 600 nodes 20 cores each with 128GBRAM</li>
<li><strong>Bianca</strong>: 200 nodes 20 cores each with 128GBRAM</li>
<li>12 PB storage</li>
<li>Parallel computing with <code>SLURM</code> - many nodes calculate in parallel on something like a loop</li>
</ul>
<h3 id="how-to-access-it">How to access it?</h3>
<ul>
<li>Create user account, then a project to actually get computing power (core-hour/month)</li>
<li>You have to apply for it</li>
<li>SNIC project for computing and Uppstore project for storage system</li>
<li>ou have lowest priority if the CPU/month is depleted</li>
<li><code>ssh -Y username@clustername.uppmax.uu.se</code> to login.</li>
<li>you have to create job queues with project ID flag, cores and stuff to compute</li>
</ul>
<h2 id="slurm-work-flow">Slurm work flow</h2>
<ul>
<li>ressource manager</li>
<li>submit request:
<code>salloc -A b2015245 -p core -n 1 -t 00:05:00 # 5 minutes</code>
To see which node to get:</li>
<li><code>squeue -u &lt;user&gt;</code> show your processes</li>
<li><code>ssh -Y &lt;node_name&gt;</code> to directly get to the node</li>
<li>now you can start the process there</li>
<li>best way is to write a script</li>
<li>so request and the command line to start the program (text files)</li>
<li>include paths to input files (file path is same for every cluster)</li>
<li>or cd commands</li>
<li><code>#SBATCH -p core</code> this line is for the SLURM parameters (starting with #)</li>
<li>you can load certain programs you use first in the script. They are called module here. So a module for samtools for instance</li>
</ul>
<p>Infos at <a href="http://uppmax.uu.se/milou-user-guide">uppmax.uu.se/milou-user-guide</a></p></div>
        </div>

        <footer class="col-md-12">
            <hr>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>
            var base_url = "..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../js/base.js" defer></script>
        <script src="../search/main.js" defer></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="Search Modal" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
                <h4 class="modal-title" id="exampleModalLabel">Search</h4>
            </div>
            <div class="modal-body">
                <p>
                    From here you can search these documents. Enter
                    your search terms below.
                </p>
                <form role="form">
                    <div class="form-group">
                        <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="Keyboard Shortcuts Modal" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
                <h4 class="modal-title" id="exampleModalLabel">Keyboard Shortcuts</h4>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
